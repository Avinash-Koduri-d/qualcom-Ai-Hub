{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "272b0c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: qai-hub in c:\\users\\avinashkoduri\\miniconda3\\envs\\qai_hub\\lib\\site-packages (0.34.0)\n",
      "Requirement already satisfied: backoff>=2.2 in c:\\users\\avinashkoduri\\miniconda3\\envs\\qai_hub\\lib\\site-packages (from qai-hub) (2.2.1)\n",
      "Requirement already satisfied: deprecation in c:\\users\\avinashkoduri\\miniconda3\\envs\\qai_hub\\lib\\site-packages (from qai-hub) (2.1.0)\n",
      "Requirement already satisfied: h5py<4,>=2.10.0 in c:\\users\\avinashkoduri\\miniconda3\\envs\\qai_hub\\lib\\site-packages (from qai-hub) (3.14.0)\n",
      "Requirement already satisfied: numpy<2,>=1.22.0 in c:\\users\\avinashkoduri\\miniconda3\\envs\\qai_hub\\lib\\site-packages (from qai-hub) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\avinashkoduri\\miniconda3\\envs\\qai_hub\\lib\\site-packages (from qai-hub) (25.0)\n",
      "Requirement already satisfied: prettytable>=3.9.0 in c:\\users\\avinashkoduri\\miniconda3\\envs\\qai_hub\\lib\\site-packages (from qai-hub) (3.11.0)\n",
      "Requirement already satisfied: protobuf<=6.31.1,>=3.20 in c:\\users\\avinashkoduri\\miniconda3\\envs\\qai_hub\\lib\\site-packages (from qai-hub) (6.31.1)\n",
      "Requirement already satisfied: requests in c:\\users\\avinashkoduri\\miniconda3\\envs\\qai_hub\\lib\\site-packages (from qai-hub) (2.32.5)\n",
      "Requirement already satisfied: requests-toolbelt in c:\\users\\avinashkoduri\\miniconda3\\envs\\qai_hub\\lib\\site-packages (from qai-hub) (1.0.0)\n",
      "Requirement already satisfied: s3transfer<0.11,>=0.10.3 in c:\\users\\avinashkoduri\\miniconda3\\envs\\qai_hub\\lib\\site-packages (from qai-hub) (0.10.4)\n",
      "Requirement already satisfied: semver>=3.0 in c:\\users\\avinashkoduri\\miniconda3\\envs\\qai_hub\\lib\\site-packages (from qai-hub) (3.0.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\avinashkoduri\\miniconda3\\envs\\qai_hub\\lib\\site-packages (from qai-hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\avinashkoduri\\miniconda3\\envs\\qai_hub\\lib\\site-packages (from qai-hub) (4.14.1)\n",
      "Requirement already satisfied: botocore<2.0a.0,>=1.33.2 in c:\\users\\avinashkoduri\\miniconda3\\envs\\qai_hub\\lib\\site-packages (from s3transfer<0.11,>=0.10.3->qai-hub) (1.40.15)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\avinashkoduri\\miniconda3\\envs\\qai_hub\\lib\\site-packages (from botocore<2.0a.0,>=1.33.2->s3transfer<0.11,>=0.10.3->qai-hub) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\avinashkoduri\\miniconda3\\envs\\qai_hub\\lib\\site-packages (from botocore<2.0a.0,>=1.33.2->s3transfer<0.11,>=0.10.3->qai-hub) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in c:\\users\\avinashkoduri\\miniconda3\\envs\\qai_hub\\lib\\site-packages (from botocore<2.0a.0,>=1.33.2->s3transfer<0.11,>=0.10.3->qai-hub) (2.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\avinashkoduri\\miniconda3\\envs\\qai_hub\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<2.0a.0,>=1.33.2->s3transfer<0.11,>=0.10.3->qai-hub) (1.17.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\avinashkoduri\\miniconda3\\envs\\qai_hub\\lib\\site-packages (from prettytable>=3.9.0->qai-hub) (0.2.13)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\avinashkoduri\\miniconda3\\envs\\qai_hub\\lib\\site-packages (from requests->qai-hub) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\avinashkoduri\\miniconda3\\envs\\qai_hub\\lib\\site-packages (from requests->qai-hub) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\avinashkoduri\\miniconda3\\envs\\qai_hub\\lib\\site-packages (from requests->qai-hub) (2025.8.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\avinashkoduri\\miniconda3\\envs\\qai_hub\\lib\\site-packages (from tqdm->qai-hub) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install qai-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8fabd1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qai-hub configuration saved to C:\\Users\\Avinashkoduri/.qai_hub/client.ini\n",
      "==================== C:\\Users\\Avinashkoduri/.qai_hub/client.ini ====================\n",
      "[api]\n",
      "api_token = i0gipkrxzvzvitihcodpausougd88d75rcclytc1\n",
      "api_url = https://app.aihub.qualcomm.com\n",
      "web_url = https://app.aihub.qualcomm.com\n",
      "verbose = True\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-01 14:34:04.140 - INFO - Enabling verbose logging.\n",
      "C:\\Users\\Avinashkoduri\\miniconda3\\envs\\qai_hub\\lib\\site-packages\\qai_hub\\_cli.py:391: UserWarning: Overwriting configuration: C:\\Users\\Avinashkoduri/.qai_hub/client.ini (previous configuration saved to C:\\Users\\Avinashkoduri/.qai_hub/client.ini.bak)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "!qai-hub configure --api_token i0gipkrxzvzvitihcodpausougd88d75rcclytc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44eccb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Avinashkoduri\\miniconda3\\envs\\qai_hub\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Avinashkoduri\\miniconda3\\envs\\qai_hub\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading tmp9wzl6qq5.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 13.9M/13.9M [00:18<00:00, 785kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheduled compile job (jgdqdmze5) successfully. To see the status and results:\n",
      "    https://app.aihub.qualcomm.com/jobs/jgdqdmze5/\n",
      "\n",
      "Waiting for compile job (jgdqdmze5) completion. Type Ctrl+C to stop waiting at any time.\n",
      "    ✅ SUCCESS                          \u0007\n",
      "Scheduled profile job (j5w3lr13p) successfully. To see the status and results:\n",
      "    https://app.aihub.qualcomm.com/jobs/j5w3lr13p/\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading dataset: 154kB [00:01, 105kB/s]                            160kB/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheduled inference job (jp1wnmv8g) successfully. To see the status and results:\n",
      "    https://app.aihub.qualcomm.com/jobs/jp1wnmv8g/\n",
      "\n",
      "Waiting for inference job (jp1wnmv8g) completion. Type Ctrl+C to stop waiting at any time.\n",
      "    ✅ SUCCESS                          \u0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tmpiuk5h3op.h5: 100%|\u001b[34m██████████\u001b[0m| 14.5k/14.5k [00:00<00:00, 613kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-5 On-Device predictions:\n",
      "968 b'cup'                71.3%\n",
      "504 b'coffee mug'         16.4%\n",
      "967 b'espresso'            7.8%\n",
      "809 b'soup bowl'           1.4%\n",
      "659 b'mixing bowl'         1.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mobilenet_v2.onnx.onnx.zip: 100%|\u001b[34m██████████\u001b[0m| 12.4M/12.4M [00:02<00:00, 4.54MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded model to mobilenet_v2.onnx.onnx.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'mobilenet_v2.onnx.onnx.zip'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision.models import mobilenet_v2\n",
    "\n",
    "import qai_hub as hub\n",
    "\n",
    "# Using pre-trained MobileNet\n",
    "torch_model = mobilenet_v2(pretrained=True)\n",
    "torch_model.eval()\n",
    "\n",
    "# Step 1: Trace model\n",
    "input_shape = (1, 3, 224, 224)\n",
    "example_input = torch.rand(input_shape)\n",
    "traced_torch_model = torch.jit.trace(torch_model, example_input)\n",
    "\n",
    "# Step 2: Compile model\n",
    "compile_job = hub.submit_compile_job(\n",
    "    model=traced_torch_model,\n",
    "    device=hub.Device(\"Snapdragon X Elite CRD\"),\n",
    "    input_specs=dict(image=input_shape),\n",
    "    options=\"--target_runtime onnx\",\n",
    ")\n",
    "assert isinstance(compile_job, hub.CompileJob)\n",
    "\n",
    "# Step 3: Profile on cloud-hosted device\n",
    "target_model = compile_job.get_target_model()\n",
    "assert isinstance(target_model, hub.Model)\n",
    "profile_job = hub.submit_profile_job(\n",
    "    model=target_model,\n",
    "    device=hub.Device(\"Snapdragon X Elite CRD\"),\n",
    ")\n",
    "assert isinstance(profile_job, hub.ProfileJob)\n",
    "\n",
    "\n",
    "# Step 4: Run inference on cloud-hosted device\n",
    "sample_image_url = (\n",
    "    \"https://qaihub-public-assets.s3.us-west-2.amazonaws.com/apidoc/input_image1.jpg\"\n",
    ")\n",
    "response = requests.get(sample_image_url, stream=True)\n",
    "response.raw.decode_content = True\n",
    "image = Image.open(response.raw).resize((224, 224))\n",
    "input_array = np.expand_dims(\n",
    "    np.transpose(np.array(image, dtype=np.float32) / 255.0, (2, 0, 1)), axis=0\n",
    ")\n",
    "\n",
    "# Run inference using the on-device model on the input image\n",
    "inference_job = hub.submit_inference_job(\n",
    "    model=target_model,\n",
    "    device=hub.Device(\"Snapdragon X Elite CRD\"),\n",
    "    inputs=dict(image=[input_array]),\n",
    ")\n",
    "assert isinstance(inference_job, hub.InferenceJob)\n",
    "\n",
    "on_device_output = inference_job.download_output_data()\n",
    "assert isinstance(on_device_output, dict)\n",
    "\n",
    "# Step 5: Post-processing the on-device output\n",
    "output_name = list(on_device_output.keys())[0]\n",
    "out = on_device_output[output_name][0]\n",
    "on_device_probabilities = np.exp(out) / np.sum(np.exp(out), axis=1)\n",
    "\n",
    "# Read the class labels for imagenet\n",
    "sample_classes = \"https://qaihub-public-assets.s3.us-west-2.amazonaws.com/apidoc/imagenet_classes.txt\"\n",
    "response = requests.get(sample_classes, stream=True)\n",
    "response.raw.decode_content = True\n",
    "categories = [str(s.strip()) for s in response.raw]\n",
    "\n",
    "# Print top five predictions for the on-device model\n",
    "print(\"Top-5 On-Device predictions:\")\n",
    "top5_classes = np.argsort(on_device_probabilities[0], axis=0)[-5:]\n",
    "for c in reversed(top5_classes):\n",
    "    print(f\"{c} {categories[c]:20s} {on_device_probabilities[0][c]:>6.1%}\")\n",
    "\n",
    "# Step 6: Download model\n",
    "target_model = compile_job.get_target_model()\n",
    "assert isinstance(target_model, hub.Model)\n",
    "target_model.download(\"mobilenet_v2.onnx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qai_hub",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
